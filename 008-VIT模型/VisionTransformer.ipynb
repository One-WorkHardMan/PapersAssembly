{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8]) tensor([[[ -1.3809,  -7.0244, -11.3916,   1.2869,  -4.8444, -10.3671,   5.6118,\n",
      "           -5.1508],\n",
      "         [ -4.9834,   0.0358, -15.2544,   3.6685,   8.6017,  -1.5891,   3.9160,\n",
      "            6.3533],\n",
      "         [-10.0968,   7.3256,  -0.7721,  -9.0098,   1.3375,  -0.2726,   3.7006,\n",
      "            1.3974],\n",
      "         [  8.0559,   5.9025,   0.8293,  -2.0891, -14.0389,   4.1494,  -2.2285,\n",
      "           -4.6619]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 第一种方式，直接图像分块：\n",
    "def image2emb_naive(image,patch_size,weight):\n",
    "    #unfold 函数的返回值[N,C*W*H,L]\n",
    "    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size).transpose(-1,-2)\n",
    "    #图像拆分成patch之后，和权重矩阵相乘，就得到了每个batch Embedding之后的维度：\n",
    "    patch_embedding = torch.matmul(patch,weight)\n",
    "\n",
    "    return patch_embedding\n",
    "\n",
    "bs,ic,image_h,image_w = 1,3,8,8\n",
    "patch_size = 4\n",
    "model_dim = 8 #目标要输出的通道数目；\n",
    "patch_depth = patch_size*patch_size*ic\n",
    "image = torch.randn(bs,ic,image_h,image_w)\n",
    "weight = torch.randn(patch_depth,model_dim)\n",
    "\n",
    "patch_embedding_navie = image2emb_naive(image,patch_size,weight)\n",
    "print(patch_embedding_navie.shape,patch_embedding_navie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 8]) tensor([[[ -1.3809,  -7.0244, -11.3916,   1.2869,  -4.8444, -10.3671,   5.6118,\n",
      "           -5.1508],\n",
      "         [ -4.9834,   0.0358, -15.2544,   3.6685,   8.6017,  -1.5891,   3.9160,\n",
      "            6.3533],\n",
      "         [-10.0968,   7.3256,  -0.7721,  -9.0098,   1.3375,  -0.2726,   3.7006,\n",
      "            1.3974],\n",
      "         [  8.0559,   5.9025,   0.8293,  -2.0891, -14.0389,   4.1494,  -2.2285,\n",
      "           -4.6619]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 第二种方式，卷积的方式：\n",
    "def image2emb_conv(image,kernel,stride):\n",
    "    conv_output = F.conv2d(image,kernel,stride=stride)\n",
    "    bs,oc,ow,oh = conv_output.shape\n",
    "\n",
    "    # 还是那个事，transfomer的输入形状是 NLC，L在图像中就是 W*H ，也就是序列长度；\n",
    "    patch_embedding = conv_output.reshape((bs,oc,ow*oh)).transpose(-1,-2)\n",
    "    return patch_embedding\n",
    "bs,ic,image_h,image_w = 1,3,8,8\n",
    "patch_size = 4\n",
    "model_dim = 8 #目标要输出的通道数目；\n",
    "patch_depth = patch_size*patch_size*ic\n",
    "# image = torch.randn(bs,ic,image_h,image_w)\n",
    "# weight = torch.randn(patch_depth,model_dim)\n",
    "\n",
    "kernle = weight.transpose(0,1).reshape((-1,ic,patch_size,patch_size)) #kernel要满足 oc*ic*kh*kw\n",
    "patch_embedding_conv = image2emb_conv(image,kernle,patch_size)\n",
    "print(patch_embedding_conv.shape,patch_embedding_conv)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------\n",
    "# 上面完成了图片的embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
