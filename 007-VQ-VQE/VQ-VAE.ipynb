{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from six.moves import xrange\n",
    "import umap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/170498071 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c500d02e88924dad80e4d81dd4860228"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#加载Cifir-10\n",
    "training_set = datasets.CIFAR10(root=\"data\",train=True,download=True,transform=transforms.Compose([\n",
    "    transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(1,1,1))\n",
    "]))\n",
    "\n",
    "validation_set = datasets.CIFAR10(root=\"data\",train=False,download=True,transform=transforms.Compose([\n",
    "    transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(1,1,1))\n",
    "]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#VQ 层\n",
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self,num_channels:int,embedding_dim:int,commitment_cost:float):\n",
    "        super.__init__()\n",
    "        self._embedding_dim  = embedding_dim\n",
    "        self._num_channels = num_channels\n",
    "\n",
    "        self._embedding = nn.Embedding(self._num_channels,self._embedding_dim)\n",
    "        # 给这个可学习的权重初始化，直接用这个权重作为Codebook了。这个weight: [numc,embeddim].\n",
    "        self._embedding.weight.data.uniform_(-1/self._num_channels,1/self._num_channels)\n",
    "        self._commitment_cost = commitment_cost\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,inputs:torch.Tensor):\n",
    "        inputs = inputs.permute(0,2,3,1).contiguous() #内存数据连续化\n",
    "        input_shape = inputs.shape\n",
    "\n",
    "        # 拉成二维\n",
    "        flat_input = inputs.view(-1,self._embedding_dim)\n",
    "\n",
    "        #计算距离 这里使用的事欧式距离。也是是余弦相似度。其实之间是有关系的。\n",
    "        distance = (torch.sum(flat_input**2,dim=1,keepdim=True)+\n",
    "                    torch.sum(self._embedding.weight**2,dim=1)-\n",
    "                    2*torch.matmul(flat_input,self._embedding_dim()))\n",
    "\n",
    "        #Ecoding\n",
    "        encoding_indices = torch.argmin(distance,dim=1).unsqueeze(1) #增加维度，从一行n个，变成 [n,1]\n",
    "        encodings = torch.zeros(encoding_indices.shape[0],self._num_channels,device=inputs.device) # 这个就是One-Hot阶段，生成对应的 [B*H*W,K]的过程\n",
    "\n",
    "        #生成OneHot向量，encodings前面全是 0 ，这里就是把对应的位置变成1.\n",
    "        encodings.scatter_(1,encoding_indices,1)\n",
    "\n",
    "        #Quantize and Unflatten, encodings 和 Codebook矩阵相乘，乘就来的就是 [BWH,D]这个D就是码本里面的数据，最近邻的那个中心。（聚类中心？？？）\n",
    "        quantized:torch.Tensor = torch.matmul(encodings,self._embedding_dim.weight).view(input_shape)\n",
    "\n",
    "        #Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(),inputs)\n",
    "        q_latent_loss = F.mse_loss(quantized,inputs.detach())\n",
    "        loss = q_latent_loss + e_latent_loss * self._commitment_cost\n",
    "\n",
    "        #trick 因为编码器Inputs 没有办法进行梯度的传播，也就是连续求导，所以这样写，类似于参数重整化，一个道理。\n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "\n",
    "\n",
    "        # 困惑度 ： 用来验证VQ是否在work ,这里就是信息熵。\n",
    "        avg_probs = torch.mean(encodings,dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs+1e-10)))\n",
    "\n",
    "        return loss,quantized.permute(0,3,1,2).contiguous(),perplexity,encodings\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#残差部分\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Encoder\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Decoder\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
