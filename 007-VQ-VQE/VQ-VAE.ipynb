{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from six.moves import xrange\n",
    "import umap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/170498071 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c500d02e88924dad80e4d81dd4860228"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#加载Cifir-10\n",
    "training_set = datasets.CIFAR10(root=\"data\",train=True,download=True,transform=transforms.Compose([\n",
    "    transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(1,1,1))\n",
    "]))\n",
    "\n",
    "validation_set = datasets.CIFAR10(root=\"data\",train=False,download=True,transform=transforms.Compose([\n",
    "    transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(1,1,1))\n",
    "]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#VQ 层\n",
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self,num_channels:int,embedding_dim:int,commitment_cost:float):\n",
    "        super.__init__()\n",
    "        self._embedding_dim  = embedding_dim\n",
    "        self._num_channels = num_channels\n",
    "\n",
    "        self._embedding = nn.Embedding(self._num_channels,self._embedding_dim)\n",
    "        # 给这个可学习的权重初始化，直接用这个权重作为Codebook了。这个weight: [numc,embeddim] = [k,D]\n",
    "        self._embedding.weight.data.uniform_(-1/self._num_channels,1/self._num_channels)\n",
    "        self._commitment_cost = commitment_cost\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,inputs:torch.Tensor):\n",
    "        inputs = inputs.permute(0,2,3,1).contiguous() #内存数据连续化\n",
    "        input_shape = inputs.shape\n",
    "\n",
    "        # 拉成二维\n",
    "        flat_input = inputs.view(-1,self._embedding_dim)\n",
    "\n",
    "        #计算距离 这里使用的事欧式距离。也是是余弦相似度。其实之间是有关系的。\n",
    "        distance = (torch.sum(flat_input**2,dim=1,keepdim=True)+\n",
    "                    torch.sum(self._embedding.weight**2,dim=1)-\n",
    "                    2*torch.matmul(flat_input,self._embedding_dim()))\n",
    "\n",
    "        #Ecoding\n",
    "        encoding_indices = torch.argmin(distance,dim=1).unsqueeze(1) #增加维度，从一行n个，变成 [n,1]\n",
    "        encodings = torch.zeros(encoding_indices.shape[0],self._num_channels,device=inputs.device) # 这个就是One-Hot阶段，生成对应的 [B*H*W,K]的过程\n",
    "\n",
    "        #生成OneHot向量，encodings前面全是 0 ，这里就是把对应的位置变成1.\n",
    "        encodings.scatter_(1,encoding_indices,1)\n",
    "\n",
    "        #Quantize and Unflatten, encodings 和 Codebook矩阵相乘，乘就来的就是 [BWH,D]这个D就是码本里面的数据，最近邻的那个中心。（聚类中心？？？）\n",
    "        quantized:torch.Tensor = torch.matmul(encodings,self._embedding_dim.weight).view(input_shape)\n",
    "\n",
    "        #Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(),inputs)\n",
    "        q_latent_loss = F.mse_loss(quantized,inputs.detach())\n",
    "        loss = q_latent_loss + e_latent_loss * self._commitment_cost\n",
    "\n",
    "        #trick 因为编码器Inputs 没有办法进行梯度的传播，也就是连续求导，所以这样写，类似于参数重整化，一个道理。\n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "\n",
    "\n",
    "        # 困惑度 ： 用来验证VQ是否在work ,这里就是信息熵。\n",
    "        avg_probs = torch.mean(encodings,dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs+1e-10)))\n",
    "\n",
    "        return loss,quantized.permute(0,3,1,2).contiguous(),perplexity,encodings\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#残差部分\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self,in_channels,num_hiddens,num_residual_hidden):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=in_channels,out_channels=num_residual_hidden,kernel_size=3,stride=1,padding=1,bias=False),\n",
    "\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=num_residual_hidden,out_channels=num_hiddens,kernel_size=1,stride=1,bias=False)\n",
    "        )\n",
    "    def forward(self,inputs):\n",
    "        return inputs + self.block(inputs)\n",
    "\n",
    "class ResidualStack(nn.Module):\n",
    "    def __init__(self,in_channels,num_hiddens,num_residual_hidden,num_residual_layers):\n",
    "        super().__init__()\n",
    "        self._num_residual_layers = num_residual_layers\n",
    "        # 这个写法 还挺新颖：\n",
    "        self._layers = nn.ModuleList([\n",
    "            [Residual(in_channels,num_hiddens,num_residual_hidden) for _ in range(self._num_residual_layers)]\n",
    "        ])\n",
    "    def forward(self,inputs):\n",
    "        for i in range(self._num_residual_layers):\n",
    "            inputs = self._layers[i](inputs)\n",
    "        return F.relu(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,in_channels,num_hiddens,num_residual_hidden,num_residual_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self._conv1 = nn.Conv2d(in_channels,num_hiddens//2,kernel_size=4,stride=2,padding=1)\n",
    "        self._conv2 = nn.Conv2d(in_channels=num_hiddens//2,out_channels=num_hiddens,kernel_size=4,stride=2,padding=1)\n",
    "        self._conv3 = nn.Conv2d(in_channels=num_hiddens,out_channels=num_hiddens,kernel_size=3,stride=1,padding=1)\n",
    "\n",
    "        self._residual_stack = ResidualStack(in_channels=num_hiddens,num_hiddens=num_hiddens,num_residual_layers = num_residual_layers,num_residual_hidden=num_residual_hidden)\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        x = self._conv1(inputs)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self._conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self._conv3(x)\n",
    "\n",
    "        return self._residual_stack(x)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,in_channels,num_hiddens,num_residual_hidden,num_residual_layers):\n",
    "        self._conv1 = nn.Conv2d(in_channels=in_channels,out_channels=num_hiddens,kernel_size=3,stride=1,padding=1)\n",
    "\n",
    "        self._redidual_stack = ResidualStack(in_channels=num_hiddens,num_hiddens=num_hiddens,num_residual_layers=num_residual_layers,num_residual_hidden=num_residual_hidden)\n",
    "\n",
    "        self._conv_trans_1 = nn.ConvTranspose2d(in_channels=num_hiddens,\n",
    "                                                out_channels=num_hiddens//2,\n",
    "                                                kernel_size=4,\n",
    "                                                stride=2,\n",
    "                                                padding=1)\n",
    "\n",
    "        self._conv_trans_2 = nn.ConvTranspose2d(in_channels=num_hiddens//2,\n",
    "                                                out_channels=3,\n",
    "                                                kernel_size=4,\n",
    "                                                stride=2,\n",
    "                                                padding=1)\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        x = self._conv1(inputs)\n",
    "\n",
    "        x = self._redidual_stack(x)\n",
    "\n",
    "        x = self._conv_trans_1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return self._conv_trans_2(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Train\n",
    "batch_size = 256\n",
    "num_training_updates = 15000\n",
    "\n",
    "num_hiddens = 128\n",
    "num_residual_hiddens = 32\n",
    "num_residual_layers = 2\n",
    "\n",
    "embedding_dim = 64\n",
    "num_embedding = 512\n",
    "\n",
    "commitment_cost = 0.25\n",
    "\n",
    "learning_rate = 1e-3\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_loader = DataLoader(\n",
    "    training_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validation_loader = DataLoader(\n",
    "    validation_set,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,num_hiddens,num_residual_layers,num):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
